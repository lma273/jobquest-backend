import uuid
import os
import json
import time
import asyncio
import functools
import requests
from typing import Optional, Dict, List, Union
from functools import lru_cache

import openai
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.docstore.document import Document as LangchainDocument
import uvicorn

# --- Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI ---
app = FastAPI(title="API Chatbot H·∫πn H√≤")

# --- C·∫•u h√¨nh CORS ---
app.add_middleware(
  CORSMiddleware,
  allow_origins=["*"],
  allow_credentials=True,
  allow_methods=["*"],
  allow_headers=["*"],
)

# --- C·∫•u h√¨nh model v√† ƒë∆∞·ªùng d·∫´n ---
EMBEDDING_MODEL_NAME = "keepitreal/vietnamese-sbert"
FAISS_INDEX_PATH = "faiss_final"
DATA_FILE = "chat_suggestion_res.txt"

# --- C·∫•u h√¨nh OpenRouter ---
OPENROUTER_API_KEY = "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"
OPENROUTER_MODEL = "meta-llama/llama-3.1-8b-instruct:free"  # C√≥ th·ªÉ thay b·∫±ng m√¥ h√¨nh kh√°c t·ª´ OpenRouter

# --- Load Embedding Model ---
print("ƒêang t·∫£i Embedding model...")
try:
  embedding_model = HuggingFaceEmbeddings(
    model_name=EMBEDDING_MODEL_NAME,
    model_kwargs={"device": "cpu"},
    encode_kwargs={"normalize_embeddings": True},
  )
  print("Embedding model ƒë√£ t·∫£i.")
except Exception as e:
  print(f"L·ªói nghi√™m tr·ªçng khi t·∫£i Embedding model: {e}")
  embedding_model = None
  exit()

# --- H√†m t·∫°o FAISS index ---
def create_faiss_index(file_path=DATA_FILE, vector_store_path=FAISS_INDEX_PATH):
  """T·∫°o v√† l∆∞u FAISS index t·ª´ file d·ªØ li·ªáu."""
  if embedding_model is None:
    print("L·ªói: Embedding model ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
    return None
  if not os.path.exists(file_path):
    print(f"L·ªói: File d·ªØ li·ªáu '{file_path}' kh√¥ng t·ªìn t·∫°i.")
    return None

  print(f"B·∫Øt ƒë·∫ßu t·∫°o FAISS index t·ª´ '{file_path}'...")
  try:
    with open(file_path, "r", encoding="utf-8") as f:
      raw_text = f.read().strip().split("\n\n")

    documents = []
    current_category = "unknown"
    for chunk in raw_text:
      chunk_strip = chunk.strip()
      if chunk_strip:
        if chunk_strip.startswith("[") and chunk_strip.endswith("]"):
          current_category = chunk_strip[1:-1].strip()
          print(f"Debug: Found category: {current_category}")
        else:
          lines = [line.strip() for line in chunk_strip.split("\n") if line.strip()]
          i = 0
          while i < len(lines) - 1:
            if lines[i].startswith("Q:") and lines[i + 1].startswith("A:"):
              question = lines[i][2:].strip()
              answer = lines[i + 1][2:].strip()
              if question and answer:
                documents.append(LangchainDocument(
                  page_content=question,
                  metadata={"answer": answer, "category": current_category}
                ))
              i += 2
            else:
              i += 1

    if not documents:
      print("Kh√¥ng t√¨m th·∫•y c·∫∑p Q/A h·ª£p l·ªá n√†o trong file d·ªØ li·ªáu.")
      return None

    print(f"ƒêang t·∫°o vector store v·ªõi {len(documents)} t√†i li·ªáu...")
    vector_store = FAISS.from_documents(documents, embedding_model)
    vector_store.save_local(vector_store_path)
    print(f"ƒê√£ t·∫°o v√† l∆∞u FAISS index v√†o '{vector_store_path}'.")
    return vector_store
  except Exception as e:
    print(f"L·ªói trong qu√° tr√¨nh t·∫°o FAISS index: {e}")
    return None

# --- Load FAISS Index ---
if os.path.exists(FAISS_INDEX_PATH) and embedding_model:
  print(f"ƒêang t·∫£i FAISS index t·ª´ {FAISS_INDEX_PATH}...")
  try:
    KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(
      FAISS_INDEX_PATH,
      embeddings=embedding_model,
      allow_dangerous_deserialization=True
    )
    print("FAISS index ƒë√£ t·∫£i.")
  except Exception as e:
    print(f"L·ªói khi t·∫£i FAISS index: {e}. Th·ª≠ t·∫°o l·∫°i index...")
    KNOWLEDGE_VECTOR_DATABASE = create_faiss_index(DATA_FILE, FAISS_INDEX_PATH)
    if KNOWLEDGE_VECTOR_DATABASE is None:
      print("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ t·∫£i ho·∫∑c t·∫°o FAISS index.")
      exit()
elif embedding_model:
  print(f"FAISS index t·∫°i '{FAISS_INDEX_PATH}' kh√¥ng t·ªìn t·∫°i. B·∫Øt ƒë·∫ßu t·∫°o m·ªõi...")
  KNOWLEDGE_VECTOR_DATABASE = create_faiss_index(DATA_FILE, FAISS_INDEX_PATH)
  if KNOWLEDGE_VECTOR_DATABASE is None:
    print("L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ t·∫°o FAISS index.")
    exit()
else:
  print("L·ªói nghi√™m tr·ªçng: Embedding model kh√¥ng t·∫£i ƒë∆∞·ª£c, kh√¥ng th·ªÉ ti·∫øp t·ª•c.")
  exit()

# --- Kh·ªüi t·∫°o OpenRouter Client ---
print("ƒêang kh·ªüi t·∫°o OpenRouter client...")
try:
  client = openai.OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=OPENROUTER_API_KEY,
  )

  # ƒê·ªãnh nghƒ©a READER_LLM v√† EXTRACT_LLM
  def READER_LLM(prompt: str) -> List[Dict[str, str]]:
    try:
      response = client.chat.completions.create(
        model=OPENROUTER_MODEL,
        messages=[
          {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω h·ªó tr·ª£ giao ti·∫øp h·∫πn h√≤."},
          {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        top_p=0.8,
        max_tokens=200,
        frequency_penalty=1.2,
      )
      return [{"generated_text": response.choices[0].message.content.strip()}]
    except Exception as e:
      print(f"L·ªói khi g·ªçi READER_LLM qua OpenRouter: {e}")
      return []

  def EXTRACT_LLM(prompt: str) -> List[Dict[str, str]]:
    try:
      response = client.chat.completions.create(
        model=OPENROUTER_MODEL,
        messages=[
          {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω tr√≠ch xu·∫•t th√¥ng tin."},
          {"role": "user", "content": prompt}
        ],
        temperature=0.0,
        max_tokens=100,
        frequency_penalty=1.1,
      )
      return [{"generated_text": response.choices[0].message.content.strip()}]
    except Exception as e:
      print(f"L·ªói khi g·ªçi EXTRACT_LLM qua OpenRouter: {e}")
      return []

  print("OpenRouter client v√† LLM functions (READER_LLM, EXTRACT_LLM) ƒë√£ s·∫µn s√†ng.")
except Exception as e:
  print(f"L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o OpenRouter client: {e}")
  READER_LLM = None
  EXTRACT_LLM = None
  exit()

# --- Prompt Templates ---
prompt_in_chat_format = [
  {
    "role": "system",
    "content": """B·∫°n l√† tr·ª£ l√Ω h·ªó tr·ª£ giao ti·∫øp h·∫πn h√≤, nhi·ªám v·ª• l√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n context ch·ª©a nhi·ªÅu c·∫∑p Q/A li√™n quan.

        QUY TR√åNH B·∫ÆT BU·ªòC:
        1. Context ch·ª©a c√°c c·∫∑p Q/A (ƒë·ªãnh d·∫°ng: Q: ... | A: ...).
        2. ƒê·ªçc v√† t·ªïng h·ª£p th√¥ng tin t·ª´ T·∫§T C·∫¢ c√°c c·∫∑p Q/A trong context ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi ph√π h·ª£p nh·∫•t v·ªõi c√¢u h·ªèi.
        3. N·∫øu c√≥ c·∫∑p Q/A kh·ªõp g·∫ßn v·ªõi c√¢u h·ªèi (theo ng·ªØ nghƒ©a), ∆∞u ti√™n s·ª≠ d·ª•ng √Ω ch√≠nh t·ª´ c√¢u tr·∫£ l·ªùi ƒë√≥, nh∆∞ng k·∫øt h·ª£p v·ªõi c√°c c·∫∑p kh√°c n·∫øu ph√π h·ª£p.
        4. N·∫øu context ch·ªâ c√≥ m·ªôt c·∫∑p Q/A, s·ª≠ d·ª•ng c√¢u tr·∫£ l·ªùi ƒë√≥ nh∆∞ng di·ªÖn ƒë·∫°t t·ª± nhi√™n h∆°n.
        5. N·∫øu kh√¥ng c√≥ c·∫∑p Q/A ph√π h·ª£p ho·∫∑c context tr·ªëng, tr·∫£ v·ªÅ: "M√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!"
        6. C√¢u tr·∫£ l·ªùi ph·∫£i t·ª± nhi√™n, ng·∫Øn g·ªçn, ƒë√∫ng ng·ªØ c·∫£nh h·∫πn h√≤, th√¢n thi·ªán, kh√¥ng l·∫∑p l·∫°i c√¢u h·ªèi, v√† kh√¥ng ch·ª©a k√Ω t·ª± th·ª´a.
        7. KH√îNG d·ªãch c√¢u h·ªèi ho·∫∑c tr·∫£ l·ªùi sang ti·∫øng Anh, gi·ªØ nguy√™n ti·∫øng Vi·ªát.

        V√ç D·ª§:
        Context:
        Q: T√¥i n√™n nh·∫Øn g√¨ n·∫øu h·ªç tr·∫£ l·ªùi ch·∫≠m? | A: ƒê·ª´ng nh·∫Øn d·ªìn d·∫≠p. Ch·ªù kho·∫£ng 1-2 ng√†y, sau ƒë√≥ nh·∫Øn l·∫°i nh·∫π nh√†ng: "Hey b·∫°n, cu·ªëi tu·∫ßn c√≥ g√¨ vui kh√¥ng?". N·∫øu h·ªç v·∫´n kh√¥ng tr·∫£ l·ªùi, c√≥ th·ªÉ h·ªç kh√¥ng h·ª©ng th√∫.
        Q: L√†m sao ƒë·ªÉ nh·∫Øn l·∫°i sau v√†i ng√†y m√† kh√¥ng k·ª≥? | A: Nh·∫Øn t·ª± nhi√™n, kh√¥ng t·ªè v·∫ª h·ªùn d·ªói. "Hey b·∫°n, cu·ªëi tu·∫ßn vui kh√¥ng?" ho·∫∑c "S·ª±c nh·ªõ b·ªØa m√¨nh ƒëang n√≥i v·ªÅ [ch·ªß ƒë·ªÅ]...".
        Q: N·∫øu h·ªç tr·∫£ l·ªùi ng·∫Øn, t√¥i n√™n l√†m g√¨? | A: C√≥ th·ªÉ h·ªç ƒëang b·∫≠n ho·∫∑c kh√¥ng bi·∫øt n√≥i g√¨. Th·ª≠ ƒë·∫∑t m·ªôt c√¢u h·ªèi m·ªü h∆°n, ho·∫∑c chia s·∫ª g√¨ ƒë√≥ v·ªÅ b·∫°n tr∆∞·ªõc ƒë·ªÉ kh∆°i g·ª£i.

        C√¢u h·ªèi: N·∫øu ƒë·ªëi ph∆∞∆°ng tr·∫£ l·ªùi tin nh·∫Øn ch·∫≠m th√¨ sao?
        Tr·∫£ l·ªùi: N·∫øu ƒë·ªëi ph∆∞∆°ng tr·∫£ l·ªùi ch·∫≠m, h√£y ki√™n nh·∫´n ch·ªù 1-2 ng√†y, r·ªìi nh·∫Øn l·∫°i nh·∫π nh√†ng nh∆∞: "Hey b·∫°n, cu·ªëi tu·∫ßn c√≥ g√¨ vui kh√¥ng?". N·∫øu h·ªç tr·∫£ l·ªùi ng·∫Øn ho·∫∑c kh√¥ng tr·∫£ l·ªùi, th·ª≠ ƒë·∫∑t c√¢u h·ªèi m·ªü h∆°n ƒë·ªÉ kh∆°i g·ª£i, nh∆∞ng n·∫øu t√¨nh h√¨nh kh√¥ng c·∫£i thi·ªán, c√≥ th·ªÉ h·ªç kh√¥ng th·ª±c s·ª± quan t√¢m.
        """
  },
  {"role": "user", "content": "Context:\n{context}"},
  {"role": "user", "content": "C√¢u h·ªèi: {question}"}
]

# ƒê·ªãnh d·∫°ng th·ªß c√¥ng cho RAG_PROMPT_TEMPLATE
RAG_PROMPT_TEMPLATE = """{system_prompt}

Context:
{context}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi: """
system_prompt = prompt_in_chat_format[0]["content"]
print("RAG_PROMPT_TEMPLATE ƒë√£ ƒë∆∞·ª£c t·∫°o th·ªß c√¥ng.")

AGE_AND_LOCATION_EXTRACTION_PROMPT = [
  {
    "role": "system",
    "content": """B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh, nhi·ªám v·ª• l√† tr√≠ch xu·∫•t ƒë·ªô tu·ªïi t·ªëi thi·ªÉu (minAge), ƒë·ªô tu·ªïi t·ªëi ƒëa (maxAge), v√† ƒë·ªãa ƒëi·ªÉm (location) t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng. Tr·∫£ l·ªùi **CH·ªà D∆Ø·ªöI D·∫†NG JSON** v·ªõi ba tr∆∞·ªùng: "minAge", "maxAge", v√† "location". KH√îNG tr·∫£ v·ªÅ b·∫•t k·ª≥ n·ªôi dung n√†o ngo√†i JSON (kh√¥ng gi·∫£i th√≠ch, kh√¥ng code, kh√¥ng vƒÉn b·∫£n kh√°c).

        QUY T·∫ÆC:
        - N·∫øu c√¢u h·ªèi c√≥ "tr√™n X tu·ªïi" ho·∫∑c "l·ªõn h∆°n X tu·ªïi", ƒë·∫∑t "minAge": X (s·ªë nguy√™n), "maxAge": null.
        - N·∫øu c√¢u h·ªèi c√≥ "d∆∞·ªõi X tu·ªïi" ho·∫∑c "nh·ªè h∆°n X tu·ªïi", ƒë·∫∑t "minAge": null, "maxAge": X (s·ªë nguy√™n).
        - N·∫øu c√¢u h·ªèi c√≥ "t·ª´ X ƒë·∫øn Y tu·ªïi" ho·∫∑c "trong kho·∫£ng X ƒë·∫øn Y tu·ªïi", ƒë·∫∑t "minAge": X (s·ªë nguy√™n), "maxAge": Y (s·ªë nguy√™n).
        - N·∫øu kh√¥ng c√≥ th√¥ng tin ƒë·ªô tu·ªïi, ƒë·∫∑t "minAge": null, "maxAge": null.
        - Ch·ªâ tr√≠ch xu·∫•t **t√™n ƒë·ªãa ƒëi·ªÉm C·ª§ TH·ªÇ** t·ª´ danh s√°ch sau: H√† N·ªôi, TP H·ªì Ch√≠ Minh, H·∫£i Ph√≤ng, ƒê√† N·∫µng, C·∫ßn Th∆°, An Giang, B√† R·ªãa - V≈©ng T√†u, B·∫Øc Giang, B·∫Øc K·∫°n, B·∫°c Li√™u, B·∫Øc Ninh, B·∫øn Tre, B√¨nh ƒê·ªãnh, B√¨nh D∆∞∆°ng, B√¨nh Ph∆∞·ªõc, B√¨nh Thu·∫≠n, C√† Mau, Cao B·∫±ng, ƒê·∫Øk L·∫Øk, ƒê·∫Øk N√¥ng, ƒêi·ªán Bi√™n, ƒê·ªìng Nai, ƒê·ªìng Th√°p, Gia Lai, H√† Giang, H√† Nam, H√† Tƒ©nh, H·∫£i D∆∞∆°ng, H·∫≠u Giang, H√≤a B√¨nh, H∆∞ng Y√™n, Kh√°nh H√≤a, Ki√™n Giang, Kon Tum, Lai Ch√¢u, L√¢m ƒê·ªìng, L·∫°ng S∆°n, L√†o Cai, Long An, Nam ƒê·ªãnh, Ngh·ªá An, Ninh B√¨nh, Ninh Thu·∫≠n, Ph√∫ Th·ªç, Ph√∫ Y√™n, Qu·∫£ng B√¨nh, Qu·∫£ng Nam, Qu·∫£ng Ng√£i, Qu·∫£ng Ninh, Qu·∫£ng Tr·ªã, S√≥c TrƒÉng, S∆°n La, T√¢y Ninh, Th√°i B√¨nh, Th√°i Nguy√™n, Thanh H√≥a, Th·ª´a Thi√™n Hu·∫ø, Ti·ªÅn Giang, Tr√† Vinh, Tuy√™n Quang, Vƒ©nh Long, Vƒ©nh Ph√∫c, Y√™n B√°i.
        - Chu·∫©n h√≥a t√™n ƒë·ªãa ƒëi·ªÉm theo danh s√°ch tr√™n (v√≠ d·ª•: "TP HCM", "S√†i G√≤n", "HCM" -> "TP H·ªì Ch√≠ Minh").
        - N·∫øu ƒë·ªãa ƒëi·ªÉm kh√¥ng n·∫±m trong danh s√°ch ho·∫∑c kh√¥ng ƒë∆∞·ª£c n√™u r√µ (v√≠ d·ª•: "g·∫ßn ƒë√¢y", "·ªü ngo√†i"), ƒë·∫∑t "location": null.
        - KH√îNG suy di·ªÖn ho·∫∑c ƒëo√°n ƒë·ªãa ƒëi·ªÉm. Ch·ªâ tr√≠ch xu·∫•t n·∫øu t√™n ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c n√™u r√µ trong c√¢u h·ªèi.
        - Tu·ªïi ph·∫£i l√† s·ªë nguy√™n (int). S·ª≠ d·ª•ng null cho c√°c tr∆∞·ªùng kh√¥ng c√≥ th√¥ng tin.

        V√ç D·ª§:
        - "T√¨m ng∆∞·ªùi tr√™n 17 tu·ªïi" -> {"minAge": 17, "maxAge": null, "location": null}
        - "T√¨m ng∆∞·ªùi d∆∞·ªõi 20 tu·ªïi ·ªü H√† N·ªôi" -> {"minAge": null, "maxAge": 20, "location": "H√† N·ªôi"}
        - "Filter T√¨m ng∆∞·ªùi trong kho·∫£ng 10 ƒë·∫øn 30 tu·ªïi s·ªëng t·∫°i TP HCM" -> {"minAge": 10, "maxAge": 30, "location": "TP H·ªì Ch√≠ Minh"}
        - "T√¥i n√™n nh·∫Øn g√¨ ƒë·∫ßu ti√™n?" -> {"minAge": null, "maxAge": null, "location": null}
        - "G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm h·∫πn h√≤ g·∫ßn ƒë√¢y?" -> {"minAge": null, "maxAge": null, "location": null}
        """
  },
  {"role": "user", "content": "C√¢u h·ªèi: {question}"},
]
# --- T·ª´ ƒëi·ªÉn √°nh x·∫° ƒë·ªãa ƒëi·ªÉm ---
LOCATION_MAPPING = {
  # H√† N·ªôi
  "h√† n·ªôi": "H√† N·ªôi",
  "hn": "H√† N·ªôi",
  "ha noi": "H√† N·ªôi",
  # TP H·ªì Ch√≠ Minh
  "tp h·ªì ch√≠ minh": "TP H·ªì Ch√≠ Minh",
  "tp hcm": "TP H·ªì Ch√≠ Minh",
  "hcm": "TP H·ªì Ch√≠ Minh",
  "s√†i g√≤n": "TP H·ªì Ch√≠ Minh",
  "sai gon": "TP H·ªì Ch√≠ Minh",
  "ho chi minh": "TP H·ªì Ch√≠ Minh",
  # H·∫£i Ph√≤ng
  "h·∫£i ph√≤ng": "H·∫£i Ph√≤ng",
  "hp": "H·∫£i Ph√≤ng",
  "hai phong": "H·∫£i Ph√≤ng",
  # ƒê√† N·∫µng
  "ƒë√† n·∫µng": "ƒê√† N·∫µng",
  "da nang": "ƒê√† N·∫µng",
  "dn": "ƒê√† N·∫µng",
  # C·∫ßn Th∆°
  "c·∫ßn th∆°": "C·∫ßn Th∆°",
  "can tho": "C·∫ßn Th∆°",
  # C√°c t·ªânh kh√°c
  "an giang": "An Giang",
  "b√† r·ªãa - v≈©ng t√†u": "B√† R·ªãa - V≈©ng T√†u",
  "b√† r·ªãa v≈©ng t√†u": "B√† R·ªãa - V≈©ng T√†u",
  "ba ria vung tau": "B√† R·ªãa - V≈©ng T√†u",
  "b·∫Øc giang": "B·∫Øc Giang",
  "bac giang": "B·∫Øc Giang",
  "b·∫Øc k·∫°n": "B·∫Øc K·∫°n",
  "bac kan": "B·∫Øc K·∫°n",
  "b·∫°c li√™u": "B·∫°c Li√™u",
  "bac lieu": "B·∫°c Li√™u",
  "b·∫Øc ninh": "B·∫Øc Ninh",
  "bac ninh": "B·∫Øc Ninh",
  "b·∫øn tre": "B·∫øn Tre",
  "ben tre": "B·∫øn Tre",
  "b√¨nh ƒë·ªãnh": "B√¨nh ƒê·ªãnh",
  "binh dinh": "B√¨nh ƒê·ªãnh",
  "b√¨nh d∆∞∆°ng": "B√¨nh D∆∞∆°ng",
  "binh duong": "B√¨nh D∆∞∆°ng",
  "b√¨nh ph∆∞·ªõc": "B√¨nh Ph∆∞·ªõc",
  "binh phuoc": "B√¨nh Ph∆∞·ªõc",
  "b√¨nh thu·∫≠n": "B√¨nh Thu·∫≠n",
  "binh thuan": "B√¨nh Thu·∫≠n",
  "c√† mau": "C√† Mau",
  "ca mau": "C√† Mau",
  "cao b·∫±ng": "Cao B·∫±ng",
  "cao bang": "Cao B·∫±ng",
  "ƒë·∫Øk l·∫Øk": "ƒê·∫Øk L·∫Øk",
  "dak lak": "ƒê·∫Øk L·∫Øk",
  "ƒë·∫Øk n√¥ng": "ƒê·∫Øk N√¥ng",
  "dak nong": "ƒê·∫Øk N√¥ng",
  "ƒëi·ªán bi√™n": "ƒêi·ªán Bi√™n",
  "dien bien": "ƒêi·ªán Bi√™n",
  "ƒë·ªìng nai": "ƒê·ªìng Nai",
  "dong nai": "ƒê·ªìng Nai",
  "ƒë·ªìng th√°p": "ƒê·ªìng Th√°p",
  "dong thap": "ƒê·ªìng Th√°p",
  "gia lai": "Gia Lai",
  "h√† giang": "H√† Giang",
  "ha giang": "H√† Giang",
  "h√† nam": "H√† Nam",
  "ha nam": "H√† Nam",
  "h√† tƒ©nh": "H√† Tƒ©nh",
  "ha tinh": "H√† Tƒ©nh",
  "h·∫£i d∆∞∆°ng": "H·∫£i D∆∞∆°ng",
  "hai duong": "H·∫£i D∆∞∆°ng",
  "h·∫≠u giang": "H·∫≠u Giang",
  "hau giang": "H·∫≠u Giang",
  "h√≤a b√¨nh": "H√≤a B√¨nh",
  "hoa binh": "H√≤a B√¨nh",
  "h∆∞ng y√™n": "H∆∞ng Y√™n",
  "hung yen": "H∆∞ng Y√™n",
  "kh√°nh h√≤a": "Kh√°nh H√≤a",
  "khanh hoa": "Kh√°nh H√≤a",
  "ki√™n giang": "Ki√™n Giang",
  "kien giang": "Ki√™n Giang",
  "kon tum": "Kon Tum",
  "lai ch√¢u": "Lai Ch√¢u",
  "lai chau": "Lai Ch√¢u",
  "l√¢m ƒë·ªìng": "L√¢m ƒê·ªìng",
  "lam dong": "L√¢m ƒê·ªìng",
  "l·∫°ng s∆°n": "L·∫°ng S∆°n",
  "lang son": "L·∫°ng S∆°n",
  "l√†o cai": "L√†o Cai",
  "lao cai": "L√†o Cai",
  "long an": "Long An",
  "nam ƒë·ªãnh": "Nam ƒê·ªãnh",
  "nam dinh": "Nam ƒê·ªãnh",
  "ngh·ªá an": "Ngh·ªá An",
  "nghe an": "Ngh·ªá An",
  "ninh b√¨nh": "Ninh B√¨nh",
  "ninh binh": "Ninh B√¨nh",
  "ninh thu·∫≠n": "Ninh Thu·∫≠n",
  "ninh thuan": "Ninh Thu·∫≠n",
  "ph√∫ th·ªç": "Ph√∫ Th·ªç",
  "phu tho": "Ph√∫ Th·ªç",
  "ph√∫ y√™n": "Ph√∫ Y√™n",
  "phu yen": "Ph√∫ Y√™n",
  "qu·∫£ng b√¨nh": "Qu·∫£ng B√¨nh",
  "quang binh": "Qu·∫£ng B√¨nh",
  "qu·∫£ng nam": "Qu·∫£ng Nam",
  "quang nam": "Qu·∫£ng Nam",
  "qu·∫£ng ng√£i": "Qu·∫£ng Ng√£i",
  "quang ngai": "Qu·∫£ng Ng√£i",
  "qu·∫£ng ninh": "Qu·∫£ng Ninh",
  "quang ninh": "Qu·∫£ng Ninh",
  "qu·∫£ng tr·ªã": "Qu·∫£ng Tr·ªã",
  "quang tri": "Qu·∫£ng Tr·ªã",
  "s√≥c trƒÉng": "S√≥c TrƒÉng",
  "soc trang": "S√≥c TrƒÉng",
  "s∆°n la": "S∆°n La",
  "son la": "S∆°n La",
  "t√¢y ninh": "T√¢y Ninh",
  "tay ninh": "T√¢y Ninh",
  "th√°i b√¨nh": "Th√°i B√¨nh",
  "thai binh": "Th√°i B√¨nh",
  "th√°i nguy√™n": "Th√°i Nguy√™n",
  "thai nguyen": "Th√°i Nguy√™n",
  "thanh h√≥a": "Thanh H√≥a",
  "thanh hoa": "Thanh H√≥a",
  "th·ª´a thi√™n hu·∫ø": "Th·ª´a Thi√™n Hu·∫ø",
  "thua thien hue": "Th·ª´a Thi√™n Hu·∫ø",
  "ti·ªÅn giang": "Ti·ªÅn Giang",
  "tien giang": "Ti·ªÅn Giang",
  "tr√† vinh": "Tr√† Vinh",
  "tra vinh": "Tr√† Vinh",
  "tuy√™n quang": "Tuy√™n Quang",
  "tuyen quang": "Tuy√™n Quang",
  "vƒ©nh long": "Vƒ©nh Long",
  "vinh long": "Vƒ©nh Long",
  "vƒ©nh ph√∫c": "Vƒ©nh Ph√∫c",
  "vinh phuc": "Vƒ©nh Ph√∫c",
  "y√™n b√°i": "Y√™n B√°i",
  "yen bai": "Y√™n B√°i",
}

# --- H√†m chu·∫©n h√≥a ƒë·ªãa ƒëi·ªÉm ---
def normalize_location(location: str) -> Optional[str]:
  if not location or not isinstance(location, str):
    return None
  # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng v√† b·ªè d·∫•u c√°ch th·ª´a
  normalized = location.lower().strip()
  # √Ånh x·∫° ƒë·ªãa ƒëi·ªÉm
  return LOCATION_MAPPING.get(normalized, None)
# --- H√†m tr√≠ch xu·∫•t tu·ªïi v√† ƒë·ªãa ƒëi·ªÉm ---
def extract_age_from_question(question: str):
  """Tr√≠ch xu·∫•t tu·ªïi v√† ƒë·ªãa ƒëi·ªÉm t·ª´ c√¢u h·ªèi s·ª≠ d·ª•ng EXTRACT_LLM."""
  if EXTRACT_LLM is None:
    print("L·ªói: EXTRACT_LLM ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
    return None, None, None

  print(f"Debug: B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t ƒë·ªô tu·ªïi v√† ƒë·ªãa ƒëi·ªÉm t·ª´ c√¢u h·ªèi: {question}")
  prompt_with_question = [
    {"role": "system", "content": AGE_AND_LOCATION_EXTRACTION_PROMPT[0]["content"]},
    {"role": "user", "content": f"C√¢u h·ªèi: {question}"},
  ]
  try:
    final_prompt = (
      f"{AGE_AND_LOCATION_EXTRACTION_PROMPT[0]['content']}\n\n"
      f"C√¢u h·ªèi: {question}\n\nTr·∫£ l·ªùi:"
    )
    response = EXTRACT_LLM(final_prompt)

    if response and isinstance(response, list) and "generated_text" in response[0]:
      result_text = response[0]["generated_text"]
      print(f"Debug: K·∫øt qu·∫£ JSON th√¥ t·ª´ LLM - {result_text}")
      try:
        json_start = result_text.find('{')
        json_end = result_text.rfind('}') + 1
        if json_start != -1 and json_end != -1:
          json_str = result_text[json_start:json_end]
          age_location_data = json.loads(json_str)
          min_age = age_location_data.get("minAge")
          max_age = age_location_data.get("maxAge")
          location = age_location_data.get("location")
          min_age = int(min_age) if min_age is not None else None
          max_age = int(max_age) if max_age is not None else None

          # Chu·∫©n h√≥a ƒë·ªãa ƒëi·ªÉm
          if location:
            normalized_location = normalize_location(location)
            if normalized_location:
              print(f"Debug: Chu·∫©n h√≥a ƒë·ªãa ƒëi·ªÉm '{location}' th√†nh '{normalized_location}'")
              location = normalized_location
            else:
              print(f"Debug: ƒê·ªãa ƒëi·ªÉm '{location}' kh√¥ng kh·ªõp v·ªõi danh s√°ch, tr·∫£ v·ªÅ null")
              location = None
          else:
            print(f"Debug: Kh√¥ng c√≥ ƒë·ªãa ƒëi·ªÉm trong k·∫øt qu·∫£, tr·∫£ v·ªÅ null")
            location = None

          print(f"Debug: Tr√≠ch xu·∫•t th√†nh c√¥ng - minAge={min_age}, maxAge={max_age}, location={location}")
          return min_age, max_age, location
        else:
          print("Debug: Kh√¥ng t√¨m th·∫•y JSON h·ª£p l·ªá trong k·∫øt qu·∫£ LLM.")
          return None, None, None
      except json.JSONDecodeError as e:
        print(f"Debug: L·ªói parse JSON t·ª´ k·∫øt qu·∫£ LLM: {e} - Result text: {result_text}")
        return None, None, None
      except ValueError as e:
        print(f"Debug: L·ªói chuy·ªÉn ƒë·ªïi tu·ªïi sang int: {e}")
        return None, None, None
    else:
      print("Debug: LLM kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá.")
      return None, None, None
  except Exception as e:
    print(f"L·ªói trong qu√° tr√¨nh tr√≠ch xu·∫•t tu·ªïi/ƒë·ªãa ƒëi·ªÉm: {e}")
    return None, None, None

# --- H√†m ph√¢n lo·∫°i c√¢u h·ªèi ---
def classify_question_category(question: str) -> Optional[str]:
  question = question.lower()
  meeting_safety_keywords = [
    "an to√†n khi g·∫∑p", "g·∫∑p m·∫∑t l·∫ßn ƒë·∫ßu", "ch√∫ √Ω khi g·∫∑p", "ch·ªó n√†o g·∫∑p", "g·∫∑p ·ªü ƒë√¢u", "an to√†n l·∫ßn ƒë·∫ßu", "g·∫∑p m·∫∑t an to√†n"
  ]
  advice_caution_keywords = ["ch√∫ √Ω", "an to√†n", "n√™n l√†m g√¨", "l√†m sao", "c·∫©n th·∫≠n", "tr√°nh", "l∆∞u √Ω", "ƒë·ªÅ ph√≤ng"]
  general_safety_keywords = [
    "b·∫£o m·∫≠t", "tin t∆∞·ªüng", "s·ªë ƒëi·ªán tho·∫°i", "l·ª´a ƒë·∫£o", "gi·∫£ m·∫°o", "b√°o c√°o", "ch·∫∑n", "block", "ri√™ng t∆∞", "c·∫©n tr·ªçng", " inf c√° nh√¢n"
  ]
  start_conversation_keywords = [
    "ƒë·∫ßu ti√™n", "m·ªõi gh√©p ƒë√¥i", "nh·∫Øn g√¨", "m·ªü l·ªùi", "b·∫Øt ƒë·∫ßu", "b·∫Øt chuy·ªán", "l√†m quen", "ch√†o h·ªèi"
  ]
  communication_dating_keywords = [
    "tr√≤ chuy·ªán", "h·∫πn h√≤", "g·∫∑p m·∫∑t", "r·ªß ƒëi", "th√∫ v·ªã", "nh·∫Øn tin", "n√≥i chuy·ªán", "duy tr√¨", "h·∫•p d·∫´n",
    "ph·∫£n h·ªìi ch·∫≠m", "ch·∫≠m", "nh·∫Øn tin ch·∫≠m", "rep ch·∫≠m", "ƒë·ªçc nh∆∞ng kh√¥ng tr·∫£ l·ªùi", "seen nh∆∞ng kh√¥ng rep",
    "ch·ªù tin nh·∫Øn", "m·∫•t h·ª©ng th√∫", "b·ªã l∆°", "b·ªã ng√≥ l∆°"
  ]
  end_continue_keywords = [
    "ti·∫øp t·ª•c", "k·∫øt th√∫c", "chia tay", "th√≠ch nhau", "ti·∫øn tri·ªÉn", "nghi√™m t√∫c", "kh√¥ng h·ª£p", "d·ª´ng l·∫°i"
  ]
  extract_more_keywords = [
    "k·ªÉ nhi·ªÅu", "k·ªÉ th√™m", "m·ªü l√≤ng", "chia s·∫ª th√™m", "k·ªÉ chuy·ªán", "k·ªÉ v·ªÅ", "t√¢m s·ª±", "n√≥i th√™m"
  ]

  contains_meeting_word = "g·∫∑p m·∫∑t" in question or " g·∫∑p " in question or question.startswith("g·∫∑p ") or question.endswith(" g·∫∑p")
  contains_advice_word = any(keyword in question for keyword in advice_caution_keywords)
  if any(keyword in question for keyword in meeting_safety_keywords):
    print("Debug: Classified by specific meeting safety keywords")
    return "B·∫£o m·∫≠t & An to√†n khi h·∫πn h√≤"
  if contains_meeting_word and contains_advice_word:
    print("Debug: Classified by meeting keyword + advice keyword")
    return "B·∫£o m·∫≠t & An to√†n khi h·∫πn h√≤"
  if any(keyword in question for keyword in general_safety_keywords):
    print("Debug: Classified by general safety keywords")
    return "B·∫£o m·∫≠t & An to√†n khi h·∫πn h√≤"
  if any(keyword in question for keyword in start_conversation_keywords):
    print("Debug: Classified by start conversation keywords")
    return "B·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán"
  if any(keyword in question for keyword in communication_dating_keywords):
    print("Debug: Classified by communication/dating keywords")
    return "Giao ti·∫øp & H·∫πn h√≤"
  if any(keyword in question for keyword in end_continue_keywords):
    print("Debug: Classified by end/continue relationship keywords")
    return "K·∫øt th√∫c ho·∫∑c ti·∫øp t·ª•c m·ªëi quan h·ªá"
  if any(keyword in question for keyword in extract_more_keywords):
    print("Debug: Classified by extract more / open up keywords")
    return "B·∫Øt ƒë·∫ßu cu·ªôc tr√≤ chuy·ªán"
  print("Debug: No specific category matched, returning None")
  return None

# --- Caching v√† Truy v·∫•n FAISS ---
@lru_cache(maxsize=1000)
def _similarity_search_internal(query_lower_strip: str, k_internal: int) -> List[LangchainDocument]:
  """H√†m sync n·ªôi b·ªô ƒë·ªÉ cache k·∫øt qu·∫£ similarity search."""
  if KNOWLEDGE_VECTOR_DATABASE is None:
    print("L·ªói: KNOWLEDGE_VECTOR_DATABASE ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
    return []
  try:
    return KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=query_lower_strip, k=k_internal)
  except Exception as e:
    print(f"L·ªói trong KNOWLEDGE_VECTOR_DATABASE.similarity_search: {e}")
    return []

async def query_faiss(question: str, k: int = 5) -> List[LangchainDocument]:
  """Truy v·∫•n FAISS b·∫•t ƒë·ªìng b·ªô v·ªõi cache."""
  query = question.lower().strip()
  loop = asyncio.get_running_loop()
  try:
    result = await loop.run_in_executor(
      None,
      functools.partial(_similarity_search_internal, query, k)
    )
    return result
  except Exception as e:
    print(f"L·ªói khi ch·∫°y query_faiss trong executor: {e}")
    return []

# --- ƒê·ªãnh nghƒ©a model request/response ---
class QuestionRequest(BaseModel):
  question: str
  userId: Optional[Union[str, int]] = None

class AnswerResponse(BaseModel):
  answer_id: str
  answer: str
  sources: List[str] = []
  is_exact: bool = False
  filter: Optional[Dict] = None

class FeedbackRequest(BaseModel):
  answer_id: str
  is_satisfied: bool
  comment: Optional[str] = None
  question: str
  answer: str

# H√†m l∆∞u ph·∫£n h·ªìi
def save_feedback(feedback: FeedbackRequest):
  feedback_data = {
    "answer_id": feedback.answer_id,
    "is_satisfied": feedback.is_satisfied,
    "comment": feedback.comment,
    "question": feedback.question,
    "answer": feedback.answer,
    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
  }
  feedback_file = "feedback.json"
  if os.path.exists(feedback_file):
    with open(feedback_file, "r", encoding="utf-8") as f:
      try:
        feedbacks = json.load(f)
      except json.JSONDecodeError:
        feedbacks = []
  else:
    feedbacks = []
  feedbacks.append(feedback_data)
  with open(feedback_file, "w", encoding="utf-8") as f:
    json.dump(feedbacks, f, ensure_ascii=False, indent=2)
  print(f"Debug: Saved feedback for answer_id={feedback.answer_id}")

# --- Decorator ƒëo th·ªùi gian ---
def measure_time(func):
  @functools.wraps(func)
  async def async_wrapper(*args, **kwargs):
    start_time = time.time()
    result = await func(*args, **kwargs)
    print(f"--- {func.__name__} took {time.time() - start_time:.2f} seconds ---")
    return result

  @functools.wraps(func)
  def sync_wrapper(*args, **kwargs):
    start_time = time.time()
    result = func(*args, **kwargs)
    print(f"--- {func.__name__} took {time.time() - start_time:.2f} seconds ---")
    return result

  return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

# --- H√†m g·ªçi LLM ---
@measure_time
def call_llm(prompt: str) -> List[Dict[str, str]]:
  """G·ªçi READER_LLM v√† x·ª≠ l√Ω l·ªói."""
  if not isinstance(prompt, str):
    print(f"L·ªói: prompt ph·∫£i l√† string, nh·∫≠n ƒë∆∞·ª£c {type(prompt)}")
    return []
  return READER_LLM(prompt)

# --- H√†m ch·ªçn top 5 c·∫∑p Q/A t·ª´ FAISS ---
def select_best_qa(question: str, retrieved_docs: List[LangchainDocument], top_n: int = 5) -> str:
  if not retrieved_docs:
    print("Debug: Kh√¥ng c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c truy xu·∫•t t·ª´ FAISS")
    return ""
  context = ""
  for i, doc in enumerate(retrieved_docs[:top_n]):
    if doc.page_content and doc.metadata.get("answer"):
      print(f"Debug: T√†i li·ªáu {i+1} - Q: {doc.page_content} | A: {doc.metadata['answer']} | Category: {doc.metadata['category']}")
      context += f"Q: {doc.page_content} | A: {doc.metadata['answer']}\n\n"
  return context.strip()

# --- API endpoint ch√≠nh ---
@measure_time
@app.post("/answer", response_model=AnswerResponse)
async def answer(request: QuestionRequest):
  print(f"\n--- New Request ---")
  print(f"Debug: Raw request - {request}")
  question = request.question
  if not question or not question.strip():
    print("Warning: Received empty or whitespace-only question.")
    return AnswerResponse(answer="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")
  print(f"Received question: {question}")
  user_id = request.userId
  print(f"Received question from user_id={user_id}")
  answer_id = str(uuid.uuid4())
  print(f"Received question: {question}, answer_id={answer_id}")

  # --- Ph·∫ßn tr√≠ch xu·∫•t tu·ªïi/ƒë·ªãa ƒëi·ªÉm v√† g·ªçi API user ---
  if question.lower().startswith("filter"):
    start_extract_time = time.time()
    min_age, max_age, location = extract_age_from_question(question)
    print(f"Debug: Age/Location extraction took {time.time() - start_extract_time:.2f} seconds")

    if min_age is not None or max_age is not None or location is not None:
      print(f"Extracted age range: {min_age} - {max_age}, location={location}")
      data = {
        "action": "find_matches",
        "id": user_id,
        "minAge": min_age,
        "maxAge": max_age,
        "location": location
      }

      try:
        response = requests.post(
          "http://localhost:8080/cupid-again/php/match_api.php",
          json=data,
          headers={"Content-Type": "application/json"}
        )
        if response.status_code == 200:
          user_list = response.json()
          if user_list:
            answer = f"C√≥ {len(user_list)} ng∆∞·ªùi "
            if min_age is not None and max_age is not None:
              answer += f"trong ƒë·ªô tu·ªïi t·ª´ {min_age} ƒë·∫øn {max_age}"
            elif min_age is not None:
              answer += f"tr√™n {min_age} tu·ªïi"
            elif max_age is not None:
              answer += f"d∆∞·ªõi {max_age} tu·ªïi"
            if location is not None:
              answer += f" v√† s·ªëng ·ªü {location}"
            answer += ". ƒêang t·∫£i danh s√°ch..."
            return AnswerResponse(
              answer_id=answer_id,
              answer=answer,
              filter={"minAge": min_age, "maxAge": max_age, "location": location},
              is_exact=True
            )
          else:
            return AnswerResponse(
              answer_id=answer_id,
              answer="Kh√¥ng t√¨m th·∫•y ng∆∞·ªùi d√πng ph√π h·ª£p v·ªõi ƒë·ªô tu·ªïi n√†y.")
        else:
          return AnswerResponse(answer="Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu ng∆∞·ªùi d√πng t·ª´ h·ªá th·ªëng.")
      except requests.RequestException as e:
        print(f"Error calling match_api.php: {e}")
        return AnswerResponse(
          answer_id=answer_id,
          answer="L·ªói khi g·ªçi h·ªá th·ªëng t√¨m ki·∫øm.")

  # --- Ph·∫ßn x·ª≠ l√Ω c√¢u h·ªèi th√¥ng th∆∞·ªùng (RAG) ---
  quick_responses = {
    "ch√†o": "Ch√†o b·∫°n! H√¥m nay b·∫°n th·∫•y th·∫ø n√†o? üòä",
    "c·∫£m ∆°n": "Kh√¥ng c√≥ g√¨, m√¨nh lu√¥n s·∫µn s√†ng gi√∫p b·∫°n! üòä",
    "hi": "Hi! R·∫•t vui ƒë∆∞·ª£c tr√≤ chuy·ªán v·ªõi b·∫°n! üòÑ",
    "hello": "Hello! B·∫°n kh·ªèe kh√¥ng? üòä",
    "t·∫°m bi·ªát": "T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i b·∫°n nh√©. üëã",
    "tr·ªùi h√¥m nay ƒë·∫πp nh·ªâ": "·ª™, tr·ªùi ƒë·∫πp th·∫≠t! B·∫°n ƒë·ªãnh l√†m g√¨ h√¥m nay? üòä"
  }
  question_lower = question.lower()
  if question_lower in quick_responses:
    print("Debug: Matched quick response.")
    time.sleep(1.5)
    return AnswerResponse(
      answer_id=answer_id,
      answer=quick_responses[question_lower]
    )

  # Ph√¢n lo·∫°i category
  predicted_category = classify_question_category(question)
  print(f"Debug: Predicted category - {predicted_category}")

  if predicted_category is None:
    print("Debug: No category matched, returning default response.")
    time.sleep(2.0)
    return AnswerResponse(
      answer_id=answer_id,
      answer="M√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!")

  # --- Step 1: Initial Retrieval from FAISS ---
  k_initial_retrieval = 15
  print(f"Debug: Retrieving top {k_initial_retrieval} candidates from FAISS...")
  start_faiss_time = time.time()
  initial_docs = await query_faiss(question, k=k_initial_retrieval)
  print(f"Debug: FAISS retrieval took {time.time() - start_faiss_time:.2f} seconds. Found {len(initial_docs)} initial docs.")

  if not initial_docs:
    return AnswerResponse(
      answer_id=answer_id,
      answer="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o li√™n quan trong c∆° s·ªü d·ªØ li·ªáu.")

  # --- Step 2: Filter by Category ---
  candidate_docs = initial_docs
  if predicted_category:
    filtered_candidate_docs = [
      doc for doc in initial_docs
      if doc.metadata.get("category") == predicted_category and doc.page_content and doc.metadata.get("answer")
    ]
    if filtered_candidate_docs:
      candidate_docs = filtered_candidate_docs
      print(f"Debug: Filtered to {len(candidate_docs)} valid docs in category '{predicted_category}'.")
    else:
      print(f"Debug: No valid docs found in category '{predicted_category}'. Checking initial docs...")
      candidate_docs = [doc for doc in initial_docs if doc.page_content and doc.metadata.get("answer")]
      if candidate_docs:
        print(f"Debug: Using {len(candidate_docs)} valid initial docs for re-ranking.")
  else:
    candidate_docs = [doc for doc in initial_docs if doc.page_content and doc.metadata.get("answer")]
    if candidate_docs:
      print(f"Debug: No category predicted. Using {len(candidate_docs)} valid initial docs for re-ranking.")

  if not candidate_docs:
    print("Debug: No valid candidate documents found after filtering.")
    return AnswerResponse(
      answer_id=answer_id,
      answer="Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p ƒë·ªÉ x·ª≠ l√Ω.")

  # --- Step 3: Prepare Context from Top 5 Documents ---
  context = select_best_qa(question, candidate_docs, top_n=5)
  print(f"Debug: Context for LLM - {context}")

  # --- Step 4: Call LLM with the refined context ---
  if READER_LLM is None:
    print("L·ªói: READER_LLM ch∆∞a s·∫µn s√†ng. Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi m·∫∑c ƒë·ªãnh.")
    return AnswerResponse(
      answer_id=answer_id,
      answer="M√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!"
    )

  final_prompt = RAG_PROMPT_TEMPLATE.format(
    system_prompt=system_prompt,
    context=context,
    question=question
  )
  response = call_llm(final_prompt)

  # --- Step 5: Process LLM Response ---
  if response and isinstance(response, list) and "generated_text" in response[0]:
    llm_generated_text = response[0]["generated_text"].strip()
    print(f"Debug: Raw text generated by LLM - '{llm_generated_text}'")

    if not llm_generated_text or llm_generated_text.lower() == "m√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!":
      print("Debug: LLM returned empty or default response. Returning default answer.")
      return AnswerResponse(
        answer_id=answer_id,
        answer="M√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!",
        sources=["FAISS Retrieval"]
      )

    return AnswerResponse(
      answer_id=answer_id,
      answer=llm_generated_text,
      sources=["FAISS Retrieval"]
    )
  else:
    print("Debug: LLM did not return a valid response. Falling back to default answer.")
    return AnswerResponse(
      answer_id=answer_id,
      answer="M√¨nh ch∆∞a c√≥ ƒë·ªß th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n th·ª≠ h·ªèi th√™m nh√©!",
      sources=["FAISS Retrieval"]
    )

# API endpoint cho ph·∫£n h·ªìi
@app.post("/feedback")
async def submit_feedback(feedback: FeedbackRequest):
  print(f"\n------ New Feedback ------")
  print(f"Debug: Feedback received - answer_id={feedback.answer_id}, is_satisfied={feedback.is_satisfied}")
  save_feedback(feedback)
  return {"message": "Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c ghi nh·∫≠n. C·∫£m ∆°n b·∫°n!"}

# --- Ch·∫°y ·ª©ng d·ª•ng ---
if __name__ == "__main__":
  print("--- Application Startup ---")
  components_ok = True
  if KNOWLEDGE_VECTOR_DATABASE is None:
    print("FATAL: FAISS index not loaded.")
    components_ok = False
  if READER_LLM is None or EXTRACT_LLM is None:
    print("FATAL: LLM Functions not loaded.")
    components_ok = False

  if components_ok:
    print("Core components (FAISS, LLM Functions) loaded successfully.")
    print(f"Starting Uvicorn server on http://127.0.0.1:8081")
    uvicorn.run(app, host="127.0.0.1", port=8081)
  else:
    print("Application startup failed due to missing components.")
