import io
import os
import json
from typing import Optional
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader
from openai import OpenAI

app = FastAPI(title="JobQuest AI Backend")

# --- 1. C·∫§U H√åNH CORS (ƒê·ªÉ Frontend React g·ªçi ƒë∆∞·ª£c) ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Trong production n√™n ƒë·ªïi th√†nh domain c·ª• th·ªÉ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 2. K·∫æT N·ªêI MONGODB ATLAS (D·ªÆ LI·ªÜU TH·∫¨T) ---
MONGO_URI = "mongodb+srv://jobquest:23020510@mal.wjbixqu.mongodb.net/?appName=mal"
DB_NAME = "ptud" # M·∫∑c ƒë·ªãnh Atlas hay d√πng 'test', b·∫°n c√≥ th·ªÉ ƒë·ªïi th√†nh t√™n DB th·∫≠t n·∫øu kh√°c
COLLECTION_JOBS = "jobs"

try:
    mongo_client = MongoClient(MONGO_URI)
    db = mongo_client[DB_NAME]
    jobs_collection = db[COLLECTION_JOBS]
    print("‚úÖ ƒê√£ k·∫øt n·ªëi t·ªõi MongoDB Atlas!")
except Exception as e:
    print(f"‚ùå L·ªói k·∫øt n·ªëi MongoDB: {e}")

# --- 3. C·∫§U H√åNH AI (OpenRouter) ---
OPENROUTER_API_KEY = "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"
# OPENROUTER_API_KEY = "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"

client_llm = OpenAI(
  base_url="https://openrouter.ai/api/v1",
  api_key=OPENROUTER_API_KEY,
)

# Load Model Embeddings (Ch·ªâ d√πng n·∫øu c·∫ßn Search Vector, ·ªü feature n√†y ch∆∞a c·∫ßn l·∫Øm)
# model = SentenceTransformer('all-MiniLM-L6-v2') 

# --- HELPER: ƒê·ªçc PDF ---
async def extract_text_from_pdf(file: UploadFile):
    try:
        content = await file.read()
        reader = PdfReader(io.BytesIO(content))
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        return text
    except Exception as e:
        print(f"L·ªói ƒë·ªçc PDF: {e}")
        return ""

# --- API 1: PH√ÇN T√çCH TR·ª∞C TI·∫æP KHI N·ªòP ƒê∆†N (QUAN TR·ªåNG NH·∫§T) ---
@app.post("/analyze_application")
async def analyze_application(
    resume: UploadFile = File(...),      # Nh·∫≠n file PDF t·ª´ form
    job_context: str = Form(...),        # Nh·∫≠n th√¥ng tin Job (Title, Desc...) d·∫°ng chu·ªói
    user_question: str = Form(default="Ph√¢n t√≠ch m·ª©c ƒë·ªô ph√π h·ª£p") # C√¢u h·ªèi t√πy ch·ªçn
):
    """
    API n√†y nh·∫≠n File CV v√† th√¥ng tin Job t·ª´ Frontend g·ª≠i l√™n (FormData).
    N√≥ ƒë·ªçc CV, so s√°nh v·ªõi Job v√† tr·∫£ v·ªÅ l·ªùi t∆∞ v·∫•n.
    """
    
    # 1. ƒê·ªçc n·ªôi dung CV t·ª´ file PDF v·ª´a upload
    cv_text = await extract_text_from_pdf(resume)
    
    if len(cv_text) < 50:
        return {"response": "‚ö†Ô∏è File CV qu√° ng·∫Øn ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung text. H√£y th·ª≠ file kh√°c."}

    # 2. Chu·∫©n b·ªã Prompt cho AI
    system_prompt = """
    B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng (HR Senior). 
    Nhi·ªám v·ª•: ƒê√°nh gi√° s·ª± ph√π h·ª£p c·ªßa ·ª©ng vi√™n d·ª±a tr√™n CV v√† JD ƒë∆∞·ª£c cung c·∫•p.
    Phong c√°ch: Ng·∫Øn g·ªçn, s√∫c t√≠ch, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ. Ch·ªâ ra ƒëi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu (Gap Analysis).
    """
    
    user_prompt = f"""
    --- TH√îNG TIN C√îNG VI·ªÜC (JOB DESCRIPTION) ---
    {job_context}
    
    --- N·ªòI DUNG CV ·ª®NG VI√äN ---
    {cv_text[:2000]} (ƒê√£ c·∫Øt g·ªçn)
    
    --- Y√äU C·∫¶U ---
    {user_question}
    
    H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
    """

    # 3. G·ªçi AI Ph√¢n t√≠ch
    try:
        completion = client_llm.chat.completions.create(
            model="meta-llama/llama-3.3-70b-instruct:free", # Ho·∫∑c model kh√°c t√πy b·∫°n ch·ªçn
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=600
        )
        ai_response = completion.choices[0].message.content
        
        return {
            "success": True,
            "cv_preview": cv_text[:200] + "...", # Tr·∫£ v·ªÅ 1 ch√∫t n·ªôi dung ƒë·ªÉ debug
            "ai_analysis": ai_response
        }

    except Exception as e:
        return {"success": False, "response": f"L·ªói g·ªçi AI: {str(e)}"}

# --- API 2: L·∫§Y DANH S√ÅCH JOB T·ª™ MONGODB (KH√îNG GI·∫¢ L·∫¨P) ---
@app.get("/jobs")
async def get_real_jobs():
    """
    L·∫•y danh s√°ch Job th·∫≠t t·ª´ MongoDB Atlas ƒë·ªÉ hi·ªÉn th·ªã l√™n Frontend (n·∫øu c·∫ßn).
    """
    try:
        # L·∫•y 50 job m·ªõi nh·∫•t
        jobs_cursor = jobs_collection.find().sort("postedAt", -1).limit(50)
        jobs = []
        for job in jobs_cursor:
            # Convert ObjectId th√†nh string ƒë·ªÉ kh√¥ng b·ªã l·ªói JSON
            job["id"] = str(job.pop("_id"))
            jobs.append(job)
        
        return jobs
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# --- C·∫≠p nh·∫≠t Data Model (Th√™m mode c√≥ default value ƒë·ªÉ kh√¥ng l·ªói frontend) ---
class ConsultRequest(BaseModel):
    cv_text: str
    job_context: str
    user_question: str
    mode: str = "candidate"  # M·∫∑c ƒë·ªãnh l√† ·ª©ng vi√™n n·∫øu frontend kh√¥ng g·ª≠i

# --- API 4: CHATBOT CONSULTANT (ƒê√É S·ª¨A LOGIC TH·∫¨T) ---
@app.post("/consult")
async def ai_consultant(req: ConsultRequest):
    """
    API t∆∞ v·∫•n ngh·ªÅ nghi·ªáp th√¥ng minh.
    Nh·∫≠n: Text CV, Ng·ªØ c·∫£nh Job, C√¢u h·ªèi.
    Tr·∫£ v·ªÅ: L·ªùi khuy√™n t·ª´ AI.
    """
    
    # 1. Ch·ªçn vai tr√≤ (Persona) cho AI
    if req.mode == "candidate":
        system_prompt = """
        B·∫°n l√† Chuy√™n gia T∆∞ v·∫•n Ngh·ªÅ nghi·ªáp (Career Coach) t·∫≠n t√¢m v√† s·∫Øc s·∫£o, ƒëang h·ªó tr·ª£ ·ª©ng vi√™n ·ª©ng tuy·ªÉn v√†o v·ªã tr√≠ c√¥ng vi·ªác (JD) ƒë∆∞·ª£c cung c·∫•p.

        NHI·ªÜM V·ª§ CH√çNH:
        1. Ph√¢n t√≠ch s·ª± ph√π h·ª£p gi·ªØa CV v√† JD (khi ƒë∆∞·ª£c h·ªèi v·ªÅ ƒë·ªô h·ª£p).
        2. T∆∞ v·∫•n c·∫£i thi·ªán CV, k·ªπ nƒÉng ph·ªèng v·∫•n, v√† deal l∆∞∆°ng (khi ƒë∆∞·ª£c h·ªèi v·ªÅ l·ªùi khuy√™n).
        3. Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ c√°c thu·∫≠t ng·ªØ, y√™u c·∫ßu trong JD.

        PHONG C√ÅCH TR·∫¢ L·ªúI:
        - Ng·∫Øn g·ªçn, s√∫c t√≠ch (d∆∞·ªõi 300 t·ª´), ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
        - Gi·ªçng ƒëi·ªáu chuy√™n nghi·ªáp, kh√≠ch l·ªá nh∆∞ng trung th·ª±c.
        - N·∫øu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng kh√¥ng li√™n quan ƒë·∫øn tuy·ªÉn d·ª•ng/c√¥ng vi·ªác, h√£y kh√©o l√©o t·ª´ ch·ªëi v√† quay l·∫°i ch·ªß ƒë·ªÅ ch√≠nh.
        - Lu√¥n tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
        """
    else:
        # D√†nh cho t∆∞∆°ng lai n·∫øu b·∫°n l√†m t√≠nh nƒÉng cho Recruiter
        system_prompt = """
        B·∫°n l√† Tr·ª£ l√Ω Tuy·ªÉn d·ª•ng (HR Assistant).
        Nhi·ªám v·ª•: ƒê√°nh gi√° nhanh ·ª©ng vi√™n n√†y c√≥ ti·ªÅm nƒÉng kh√¥ng.
        Phong c√°ch: Kh√°ch quan, t·∫≠p trung v√†o r·ªßi ro v√† ƒë√°nh gi√° nƒÉng l·ª±c c·ªët l√µi.
        """

    # 2. T·∫°o ng·ªØ c·∫£nh (Context) ƒë·ªÉ g·ª≠i cho AI
    # K·∫øt h·ª£p th√¥ng tin Job, CV v√† c√¢u h·ªèi ng∆∞·ªùi d√πng
    user_prompt = f"""
    === TH√îNG TIN C√îNG VI·ªÜC (JD) ===
    {req.job_context}
    
    === H·ªí S∆† ·ª®NG VI√äN (CV) ===
    {req.cv_text[:3000]}  # Gi·ªõi h·∫°n 3000 k√Ω t·ª± ƒë·ªÉ ti·∫øt ki·ªám token
    
    === C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG ===
    "{req.user_question}"
    
    H√£y tr·∫£ l·ªùi c√¢u h·ªèi tr√™n b·∫±ng ti·∫øng Vi·ªát.
    """

    try:
        # 3. G·ªçi OpenRouter (AI Model)
        completion = client_llm.chat.completions.create(
            model="meta-llama/llama-3.3-70b-instruct:free", # Model mi·ªÖn ph√≠ v√† r·∫•t th√¥ng minh
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=800, # ƒê·ªô d√†i c√¢u tr·∫£ l·ªùi t·ªëi ƒëa
            temperature=0.7 # ƒê·ªô s√°ng t·∫°o (0.7 l√† m·ª©c c√¢n b·∫±ng)
        )
        
        # 4. Tr·∫£ k·∫øt qu·∫£ v·ªÅ Frontend
        return {"response": completion.choices[0].message.content}
    
    except Exception as e:
        print(f"L·ªói AI: {str(e)}")
        return {"response": "Xin l·ªói, h·ªá th·ªëng AI ƒëang b·∫≠n. B·∫°n vui l√≤ng th·ª≠ l·∫°i sau gi√¢y l√°t."}

# --- C·∫≠p nh·∫≠t Data Model ---
# class JDRequest(BaseModel):
#     title: str
#     skills: str

# --- API 5: AI VI·∫æT JD CHO NH√Ä TUY·ªÇN D·ª§NG ---
# @app.post("/generate_jd")
# async def generate_jd_ai(req: JDRequest):
#     """
#     T·ª± ƒë·ªông vi·∫øt JD chuy√™n nghi·ªáp d·ª±a tr√™n v·ªã tr√≠ v√† k·ªπ nƒÉng y√™u c·∫ßu.
#     """
#     prompt = f"""
#     B·∫°n l√† chuy√™n gia nh√¢n s·ª± (HR Manager). H√£y vi·∫øt m·ªôt b·∫£n M√¥ t·∫£ c√¥ng vi·ªác (Job Description) chuy√™n nghi·ªáp cho v·ªã tr√≠: "{req.title}".
    
#     Y√™u c·∫ßu k·ªπ nƒÉng: {req.skills}
    
#     C·∫•u tr√∫c b·∫Øt bu·ªôc (d√πng Markdown):
#     1. üìù Gi·ªõi thi·ªáu chung
#     2. üöÄ Tr√°ch nhi·ªám ch√≠nh (G·∫°ch ƒë·∫ßu d√≤ng)
#     3. üéØ Y√™u c·∫ßu c√¥ng vi·ªác (D·ª±a tr√™n k·ªπ nƒÉng ƒë√£ nh·∫≠p)
#     4. üéÅ Quy·ªÅn l·ª£i (G·ª£i √Ω chung)
    
#     Vi·∫øt b·∫±ng ti·∫øng Vi·ªát, gi·ªçng vƒÉn h·∫•p d·∫´n, chuy√™n nghi·ªáp.
#     """
    
#     try:
#         completion = client_llm.chat.completions.create(
#             model="meta-llama/llama-3.3-70b-instruct:free",
#             messages=[{"role": "user", "content": prompt}]
#         )
#         return {"jd_content": completion.choices[0].message.content}
#     except Exception as e:
#         return {"jd_content": f"L·ªói AI: {str(e)}"}
# --- C·∫≠p nh·∫≠t Data Model ---
class JDGenRequest(BaseModel):
    rough_input: str # V√≠ d·ª•: "C·∫ßn tuy·ªÉn React dev, 2 nƒÉm kn, l∆∞∆°ng 1000$, l√†m ·ªü C·∫ßu Gi·∫•y"

# --- API 5 (Vi·∫øt l·∫°i): AI GEN JD T·ª™ Y√äU C·∫¶U S∆† S√ÄI ---
@app.post("/generate_jd")
async def generate_jd_ai(req: JDGenRequest):
    """
    Bi·∫øn y√™u c·∫ßu s∆° s√†i c·ªßa HR th√†nh JD chuy√™n nghi·ªáp.
    """
    prompt = f"""
    B·∫°n l√† HR Manager cao c·∫•p. H√£y vi·∫øt l·∫°i b·∫£n M√¥ t·∫£ c√¥ng vi·ªác (JD) chuy√™n nghi·ªáp d·ª±a tr√™n c√°c ghi ch√∫ th√¥ sau:
    "{req.rough_input}"
    
    Y√™u c·∫ßu ƒë·∫ßu ra (Markdown):
    1. Ti√™u ƒë·ªÅ c√¥ng vi·ªác (G·ª£i √Ω m·ªôt ti√™u ƒë·ªÅ h·∫•p d·∫´n)
    2. M√¥ t·∫£ c√¥ng vi·ªác (Vi·∫øt l·∫°i vƒÉn phong chuy√™n nghi·ªáp)
    3. Y√™u c·∫ßu (Ph√¢n t√≠ch t·ª´ ghi ch√∫ th√¥ ƒë·ªÉ suy ra k·ªπ nƒÉng c·∫ßn thi·∫øt)
    4. Quy·ªÅn l·ª£i (N·∫øu trong ghi ch√∫ kh√¥ng c√≥, h√£y g·ª£i √Ω c√°c quy·ªÅn l·ª£i ti√™u chu·∫©n ng√†nh IT)
    
    H√£y vi·∫øt b·∫±ng ti·∫øng Vi·ªát, gi·ªçng vƒÉn thu h√∫t.
    """
    
    try:
        completion = client_llm.chat.completions.create(
            model="meta-llama/llama-3.3-70b-instruct:free",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return {"jd_content": completion.choices[0].message.content}
    except Exception as e:
        return {"jd_content": f"L·ªói AI: {str(e)}"}
# Run server: uvicorn chatbot:app --reload